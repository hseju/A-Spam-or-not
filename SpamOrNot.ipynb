{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7271e228-fb94-40c2-ac54-1efce9eedeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfae53e5-baba-416c-b9b2-3ece38f57999",
   "metadata": {},
   "source": [
    "## SPAM Classifier \n",
    "\n",
    "We are going to use data provided by UCI which is open for all to use.\n",
    "\n",
    "It can be found at  https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection. \n",
    "\n",
    "Following are the steps we are going to follow:\n",
    "\n",
    "1. Get the data\n",
    "2. Preprocess the data\n",
    "3. Create train and test datasets\n",
    "4. Use Naive Bayes classifier to identify spam messages \n",
    "5. Evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2403c8c7-f560-427e-8dd1-a6bfe3247e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.classifier import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1a39e9-8752-42e2-a482-c2d2029924d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the current working directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f192f0cf-bbab-4fea-bd8f-6e028ec10b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(cwd + \"/smsspamcollection/SMSSpamCollection\", sep  =\"\\t\", names= ['label', 'messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6eecce3-c5c0-4df4-9685-84f8dcb2e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           messages\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15803d-98ef-41cb-bd51-e1c612234523",
   "metadata": {},
   "source": [
    "Lets convert the ham and spam to 0 and 1 category respectively which will be our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911fdcef-c859-42c9-90e3-7c07dfc2e202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           messages\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "5568      0               Will ü b going to esplanade fr home?\n",
       "5569      0  Pity, * was in mood for that. So...any other s...\n",
       "5570      0  The guy did some bitching but I acted like i'd...\n",
       "5571      0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = data['label'].replace({'ham':0, 'spam':1})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f7883-8a40-4f7c-8377-9ca5a9e94dee",
   "metadata": {},
   "source": [
    "## Using Porter Stemming to create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2502d1f9-6945-46e5-99b3-d5ef0357bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we wil preprocess the messages\n",
    "import re\n",
    "\n",
    "#create porter stemmer object\n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus=[]\n",
    "\n",
    "\n",
    "for sent in data['messages']:\n",
    "    #remove all punctuation\n",
    "    sent = re.sub('[^a-zA-Z]', ' ', sent)\n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    sent = [ps.stem(word) for word in sent if not word in stopwords.words(\"english\")]\n",
    "    sent = \" \".join(sent)\n",
    "    corpus.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae9870a-76d6-48b1-b438-8a86e6afeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['corpus'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ccb252-9c7d-443b-ae61-4fbfdd33cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#porter stemmed data\n",
    "data_ps = data.drop('messages', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db5ce473-91c6-4f59-b62d-ab677b2b76ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri wkli comp win fa cup final tkt st m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>nd time tri contact u u pound prize claim easi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>b go esplanad fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>piti mood suggest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>guy bitch act like interest buy someth els nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             corpus\n",
       "0         0  go jurong point crazi avail bugi n great world...\n",
       "1         0                              ok lar joke wif u oni\n",
       "2         1  free entri wkli comp win fa cup final tkt st m...\n",
       "3         0                u dun say earli hor u c alreadi say\n",
       "4         0               nah think goe usf live around though\n",
       "...     ...                                                ...\n",
       "5567      1  nd time tri contact u u pound prize claim easi...\n",
       "5568      0                              b go esplanad fr home\n",
       "5569      0                                  piti mood suggest\n",
       "5570      0  guy bitch act like interest buy someth els nex...\n",
       "5571      0                                     rofl true name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95cbea-eadf-4b7a-9519-ad468c61df6f",
   "metadata": {},
   "source": [
    "## Using Lemmatization to create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa467d2-4687-429f-ab97-f41db04b4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to store the corpus\n",
    "corpus_lemma=[]\n",
    "\n",
    "#create a lemmatizer object\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "for sent in data['messages']:\n",
    "    #remove all punctuation\n",
    "    sent = re.sub('[^a-zA-Z]', ' ', sent)\n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    sent = [lemma.lemmatize(word) for word in sent if not word in stopwords.words(\"english\")]\n",
    "    sent = \" \".join(sent)\n",
    "    corpus_lemma.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf89148c-cff1-48fe-b2a5-0c2df39c20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['corpus_lemma'] = corpus_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c671c3-d518-47b9-98d1-b4a785dd04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemma = data.drop(['messages','corpus'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56143c5-b695-43b8-9e80-e54fb2517a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>corpus_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>pity mood suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                       corpus_lemma\n",
       "0         0  go jurong point crazy available bugis n great ...\n",
       "1         0                            ok lar joking wif u oni\n",
       "2         1  free entry wkly comp win fa cup final tkts st ...\n",
       "3         0                u dun say early hor u c already say\n",
       "4         0                nah think go usf life around though\n",
       "...     ...                                                ...\n",
       "5567      1  nd time tried contact u u pound prize claim ea...\n",
       "5568      0                          b going esplanade fr home\n",
       "5569      0                               pity mood suggestion\n",
       "5570      0  guy bitching acted like interested buying some...\n",
       "5571      0                                     rofl true name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771fe33-2e70-4c82-a793-5f79d59e5515",
   "metadata": {},
   "source": [
    "## Vectorization using Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7875b9-7cc8-4032-9b68-a47635a5c335",
   "metadata": {},
   "source": [
    "#### Using Porter Stemmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90b971d4-8c86-4398-8554-f176f5a05474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(vectorizer,corpus, label):\n",
    "    #create features\n",
    "    X = vectorizer.fit_transform(corpus).toarray() \n",
    "    #create labels\n",
    "    y = label\n",
    "\n",
    "    #now splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "    #creating object for NaiveBayes\n",
    "    nb_model = MultinomialNB()\n",
    "    \n",
    "    #predicting\n",
    "    y_pred_test = nb_model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    #accuracy score\n",
    "    score = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d16feb-929d-4487-bf07-394a46702ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance of CountVecotrizer from sklearn\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6893b73-75e9-48ea-b596-49f76d85d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using Porter stemmer and Bag of Words vectorization is : 0.9721973094170404\n"
     ]
    }
   ],
   "source": [
    "score_ps_cv = model(vectorizer, data['corpus'], data['label'])\n",
    "print(\"Accuracy score using Porter stemmer and Bag of Words vectorization is : \" + str(score_ps_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df7c0e-0ecf-4bc6-ac52-091c520a754f",
   "metadata": {},
   "source": [
    "#### Using Lemmatized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73926594-84ea-467c-b8ad-41df456d236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance of CountVecotrizer from sklearn\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23b8a061-a6c6-4143-b142-b35521f1082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using Lemmantized data and Bag of Words vectorization is : 0.9721973094170404\n"
     ]
    }
   ],
   "source": [
    "score_lemma_cv = model(vectorizer,data['corpus_lemma'], data['label'])\n",
    "print(\"Accuracy score using Lemmatized data and Bag of Words vectorization is : \" + str(score_lemma_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595784bb-c650-4cfd-8952-7e264d60d312",
   "metadata": {},
   "source": [
    "## Vectorization using TFiDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609336c0-b68f-40fd-bf6a-7f111b43cb82",
   "metadata": {},
   "source": [
    "#### Using Porter Stemmer Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19b3debc-354d-4202-9af0-ada455aea34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using Porter stemmer and TFiDF vectorization is : 0.9596412556053812\n"
     ]
    }
   ],
   "source": [
    "#creating instance of Tfidf Vectorizer from sklearn\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "score_ps_tf = model(vectorizer, data['corpus'], data['label'])\n",
    "print(\"Accuracy score using Porter stemmer and TFiDF vectorization is : \" + str(score_ps_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f213f9d8-318c-44e6-93d3-2957ba933cb9",
   "metadata": {},
   "source": [
    "#### Using Lemmatized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dd8740c-18cf-409a-9e68-8cda1228a909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using Lemmatized data and Bag of Words vectorization is : 0.9605381165919282\n"
     ]
    }
   ],
   "source": [
    "#creating instance of Tfidf Vectorizer from sklearn\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "score_lemma_tf = model(vectorizer,data['corpus_lemma'], data['label'])\n",
    "print(\"Accuracy score using Lemmatized data and Bag of Words vectorization is : \" + str(score_lemma_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e43b2109-4fdc-4a6a-b0b1-2376cecdfaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_data = pd.DataFrame({'Porter Stemmer':[score_ps_cv, score_ps_tf],'Lemmatized':[score_lemma_cv, score_lemma_tf]},\n",
    "                            index=['Count_vectorizer','TFiDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef806e50-5f53-4843-86f2-032351f4a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Porter Stemmer</th>\n",
       "      <th>Lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count_vectorizer</th>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.972197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFiDF</th>\n",
       "      <td>0.959641</td>\n",
       "      <td>0.960538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Porter Stemmer  Lemmatized\n",
       "Count_vectorizer        0.972197    0.972197\n",
       "TFiDF                   0.959641    0.960538"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c993a5a-50a5-486c-9731-a185b14c173e",
   "metadata": {},
   "source": [
    "So as we can see from above table that using countVectorizer for both porter stemmed and lemmatized data gave same higher accuracy than TFiDF data. However, this can be reversible in some other cases. It depends on the corpus pre processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb0cae-4128-400c-9124-226e4cc84606",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix(y_tesst, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
